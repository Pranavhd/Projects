The training data for our model consisted of tweets and their corresponding features. The training data contains 200 tweets of each of the 6 air lines in consideration. Thus the total size of the training data is 1200 tweets. Considering 'f' features under consideration, we have the training data, as a 2 dimensional matrix of size 1200 * (f+1). Any tweet from the handle or to the specific handle is extracted. These tweets are then manualy annotated with their corresponding sentiment value. The sentiment value is a categorical in nature an consists only of value -1, 0 and 1. A sentiment value of -1,0 and 1 indicates a negative sentiment, neutral sentiment and positive sentiment respectively. The model is then trained on this training data set. 

Data was crawled from Twitter website using a number of tools. Primarily python, selenium and twitter api's were used to fetch data and store it in a readable format.